name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt

      - name: Run Black formatter check
        run: |
          black --check --diff src/ tests/

      - name: Run isort import sorting check
        run: |
          isort --check-only --diff src/ tests/

      - name: Run Flake8 linting
        run: |
          flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503 --statistics

      - name: Run mypy type checking
        run: |
          mypy src/ --ignore-missing-imports
        continue-on-error: true  # Don't fail on type errors initially

      - name: Run Bandit security checks
        run: |
          bandit -r src/ -f json -o bandit-report.json
        continue-on-error: true

      - name: Upload Bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report-${{ matrix.python-version }}
          path: bandit-report.json

  tests:
    name: Unit and Integration Tests
    runs-on: ubuntu-latest
    needs: code-quality
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt

      - name: Run pytest with coverage
        run: |
          pytest tests/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --junitxml=pytest-report.xml \
            -v

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-${{ matrix.python-version }}
          fail_ci_if_error: false

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pytest-results-${{ matrix.python-version }}
          path: |
            pytest-report.xml
            htmlcov/

  model-tests:
    name: Model Architecture Tests (CPU)
    runs-on: ubuntu-latest
    needs: code-quality

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
          pip install -r requirements.txt

      - name: Test model instantiation
        run: |
          python -c "
          import torch
          from src.models import create_model

          # Test ResNet50
          model = create_model('resnet50', num_classes=7)
          x = torch.randn(2, 3, 224, 224)
          output = model(x)
          assert output.shape == (2, 7), 'ResNet50 output shape mismatch'
          print('ResNet50 test passed')

          # Test ConvNeXt
          model = create_model('convnext_base', num_classes=7)
          output = model(x)
          assert output.shape == (2, 7), 'ConvNeXt output shape mismatch'
          print('ConvNeXt test passed')
          "

      - name: Test data loading
        run: |
          python -c "
          from src.data import get_transforms
          transforms = get_transforms('train')
          print('Data transforms created successfully')
          "

  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    needs: tests

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build development image
        uses: docker/build-push-action@v5
        with:
          context: .
          target: development
          tags: skin-cancer-classifier:dev
          cache-from: type=gha
          cache-to: type=gha,mode=max
          load: true

      - name: Build production image
        uses: docker/build-push-action@v5
        with:
          context: .
          target: production
          tags: skin-cancer-classifier:prod
          cache-from: type=gha
          cache-to: type=gha,mode=max
          load: true

      - name: Test Docker image
        run: |
          docker run --rm skin-cancer-classifier:prod python -c "import torch; print(f'PyTorch {torch.__version__}')"

  pre-commit:
    name: Pre-commit Hooks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install pre-commit
        run: |
          pip install pre-commit

      - name: Run pre-commit hooks
        run: |
          pre-commit run --all-files --show-diff-on-failure

  documentation:
    name: Documentation Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check Markdown links
        uses: gaurav-nelson/github-action-markdown-link-check@v1
        with:
          use-quiet-mode: 'yes'
          use-verbose-mode: 'no'
          config-file: '.github/markdown-link-check-config.json'
        continue-on-error: true

      - name: Check for TODOs
        run: |
          echo "Checking for TODO comments..."
          grep -r "TODO" src/ || echo "No TODOs found"

  dependency-check:
    name: Dependency Vulnerability Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install safety pip-audit

      - name: Run Safety check
        run: |
          safety check --json --output safety-report.json
        continue-on-error: true

      - name: Run pip-audit
        run: |
          pip-audit --format json --output pip-audit-report.json
        continue-on-error: true

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            safety-report.json
            pip-audit-report.json

  integration-summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [code-quality, tests, model-tests, docker-build, pre-commit]
    if: always()

    steps:
      - name: Check job results
        run: |
          echo "Code Quality: ${{ needs.code-quality.result }}"
          echo "Tests: ${{ needs.tests.result }}"
          echo "Model Tests: ${{ needs.model-tests.result }}"
          echo "Docker Build: ${{ needs.docker-build.result }}"
          echo "Pre-commit: ${{ needs.pre-commit.result }}"

      - name: Report status
        if: |
          needs.code-quality.result == 'failure' ||
          needs.tests.result == 'failure' ||
          needs.model-tests.result == 'failure'
        run: |
          echo "CI pipeline failed. Check logs for details."
          exit 1
