"""
Synthetic Dermoscopy Dataset for FairSkin.

Implements PyTorch datasets for:
1. SyntheticDermoscopyDataset: Load synthetic images generated by FairSkin
2. MixedDataset: Combine real + synthetic with FST-dependent ratios
3. Balanced sampling for training with FairDisCo + CIRCLe

Key Features:
- Load synthetic images from disk
- Mix with real HAM10000 data
- FST-dependent synthetic ratio (70-80% for FST V-VI)
- Support for FairDisCo adversarial training
- Quality filtering integration

Framework: MENDICANT_BIAS - Phase 2
Agent: HOLLOWED_EYES
Version: 0.3.0
Date: 2025-10-13
"""

import os
import warnings
from pathlib import Path
from typing import Optional, Callable, Dict, List, Union, Tuple

import torch
from torch.utils.data import Dataset, DataLoader, ConcatDataset, WeightedRandomSampler
import numpy as np
import pandas as pd
from PIL import Image
import cv2


class SyntheticDermoscopyDataset(Dataset):
    """
    Dataset for synthetic dermoscopy images generated by FairSkin.

    Expected directory structure:
    ```
    synthetic_dir/
        ├── synthetic_fst1_melanoma_00001.png
        ├── synthetic_fst1_melanoma_00002.png
        ├── synthetic_fst6_nevus_00001.png
        └── ...
    ```

    Filename format: synthetic_fst{fst}_{diagnosis}_{index:05d}.png
    """

    def __init__(
        self,
        synthetic_dir: str,
        transform: Optional[Callable] = None,
        diagnosis_mapping: Optional[Dict[str, int]] = None,
        load_to_memory: bool = False,
    ):
        """
        Initialize synthetic dataset.

        Args:
            synthetic_dir: Directory containing synthetic images
            transform: Image transformations
            diagnosis_mapping: Mapping from diagnosis names to integers
            load_to_memory: Whether to load all images to RAM (faster but memory-intensive)
        """
        self.synthetic_dir = Path(synthetic_dir)
        self.transform = transform
        self.load_to_memory = load_to_memory

        # Default diagnosis mapping (HAM10000 format)
        if diagnosis_mapping is None:
            self.diagnosis_mapping = {
                'actinic_keratosis': 0,
                'basal_cell_carcinoma': 1,
                'benign_keratosis': 2,
                'dermatofibroma': 3,
                'melanoma': 4,
                'nevus': 5,
                'vascular_lesion': 6,
            }
        else:
            self.diagnosis_mapping = diagnosis_mapping

        # Scan directory for images
        self.samples = self._scan_directory()

        # Optionally load to memory
        if load_to_memory:
            print(f"Loading {len(self.samples)} synthetic images to memory...")
            self.images_in_memory = [self._load_image(path) for path, _, _ in self.samples]
        else:
            self.images_in_memory = None

        print(f"\nSynthetic Dermoscopy Dataset")
        print(f"  Directory: {self.synthetic_dir}")
        print(f"  Total samples: {len(self.samples)}")
        print(f"  In memory: {load_to_memory}")

        # Print statistics
        self._print_statistics()

    def _scan_directory(self) -> List[Tuple[Path, int, int]]:
        """
        Scan directory and parse filenames.

        Returns:
            List of (path, diagnosis, fst) tuples
        """
        samples = []

        if not self.synthetic_dir.exists():
            raise FileNotFoundError(f"Synthetic directory not found: {self.synthetic_dir}")

        # Find all PNG images
        image_files = sorted(self.synthetic_dir.glob("*.png"))

        if len(image_files) == 0:
            warnings.warn(f"No PNG images found in {self.synthetic_dir}")
            return samples

        # Parse filenames
        for image_path in image_files:
            try:
                # Expected format: synthetic_fst{fst}_{diagnosis}_{index}.png
                parts = image_path.stem.split('_')

                if len(parts) < 3:
                    warnings.warn(f"Invalid filename format: {image_path.name}")
                    continue

                # Extract FST
                fst_part = parts[1]  # 'fst6'
                if not fst_part.startswith('fst'):
                    warnings.warn(f"Invalid FST format: {fst_part}")
                    continue
                fst = int(fst_part[3:])  # Extract number

                # Extract diagnosis
                diagnosis_name = parts[2]  # 'melanoma'
                if diagnosis_name not in self.diagnosis_mapping:
                    warnings.warn(f"Unknown diagnosis: {diagnosis_name}")
                    continue
                diagnosis = self.diagnosis_mapping[diagnosis_name]

                samples.append((image_path, diagnosis, fst))

            except Exception as e:
                warnings.warn(f"Failed to parse {image_path.name}: {e}")
                continue

        return samples

    def _load_image(self, image_path: Path) -> np.ndarray:
        """Load image as RGB array."""
        image = cv2.imread(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        return image

    def _print_statistics(self):
        """Print dataset statistics."""
        if len(self.samples) == 0:
            return

        # Count by diagnosis
        diagnosis_counts = {}
        for _, dx, _ in self.samples:
            diagnosis_counts[dx] = diagnosis_counts.get(dx, 0) + 1

        print(f"  Diagnosis distribution:")
        for dx, count in sorted(diagnosis_counts.items()):
            print(f"    Class {dx}: {count:5d} ({count/len(self.samples)*100:5.2f}%)")

        # Count by FST
        fst_counts = {}
        for _, _, fst in self.samples:
            fst_counts[fst] = fst_counts.get(fst, 0) + 1

        print(f"  FST distribution:")
        for fst, count in sorted(fst_counts.items()):
            print(f"    FST {fst}: {count:5d} ({count/len(self.samples)*100:5.2f}%)")

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int) -> Dict[str, Union[torch.Tensor, int]]:
        """
        Get dataset item.

        Returns:
            Dictionary with:
                - image: Tensor (C, H, W)
                - label: Diagnosis class (0-6)
                - fst: FST class (1-6)
                - is_synthetic: Always True (1)
        """
        image_path, diagnosis, fst = self.samples[idx]

        # Load image
        if self.images_in_memory is not None:
            image = self.images_in_memory[idx].copy()
        else:
            image = self._load_image(image_path)

        # Apply transforms
        if self.transform is not None:
            if hasattr(self.transform, '__call__'):
                try:
                    # Try albumentations
                    transformed = self.transform(image=image)
                    image = transformed['image']
                except (TypeError, KeyError):
                    # Fallback to torchvision
                    image = Image.fromarray(image)
                    image = self.transform(image)

        # Ensure tensor format
        if not isinstance(image, torch.Tensor):
            image = torch.from_numpy(image).permute(2, 0, 1).float()

        return {
            'image': image,
            'label': diagnosis,
            'fst': fst,
            'is_synthetic': 1,  # Flag for mixed training
        }

    def get_class_distribution(self) -> Dict[int, int]:
        """Get diagnosis class distribution."""
        diagnosis_counts = {}
        for _, dx, _ in self.samples:
            diagnosis_counts[dx] = diagnosis_counts.get(dx, 0) + 1
        return diagnosis_counts

    def get_fst_distribution(self) -> Dict[int, int]:
        """Get FST distribution."""
        fst_counts = {}
        for _, _, fst in self.samples:
            fst_counts[fst] = fst_counts.get(fst, 0) + 1
        return dict(sorted(fst_counts.items()))


class MixedDataset(Dataset):
    """
    Mixed dataset combining real and synthetic data.

    Implements FST-dependent synthetic ratio:
    - FST I-III: 20-30% synthetic (abundant real data)
    - FST IV: 50% synthetic
    - FST V-VI: 70-80% synthetic (scarce real data)

    This creates balanced FST representation while preserving
    diagnostic accuracy on real data.
    """

    def __init__(
        self,
        real_dataset: Dataset,
        synthetic_dataset: Dataset,
        synthetic_ratio_by_fst: Optional[Dict[int, float]] = None,
        balance_fst: bool = True,
        transform: Optional[Callable] = None,
    ):
        """
        Initialize mixed dataset.

        Args:
            real_dataset: Real dermoscopy dataset (e.g., HAM10000)
            synthetic_dataset: Synthetic dataset from FairSkin
            synthetic_ratio_by_fst: FST-dependent synthetic ratio
                Format: {fst: ratio}, e.g., {1: 0.2, 6: 0.8}
            balance_fst: Whether to balance FST distribution
            transform: Optional transforms (applied to both real and synthetic)
        """
        self.real_dataset = real_dataset
        self.synthetic_dataset = synthetic_dataset
        self.transform = transform
        self.balance_fst = balance_fst

        # Default FST-dependent synthetic ratios
        if synthetic_ratio_by_fst is None:
            self.synthetic_ratio_by_fst = {
                1: 0.2, 2: 0.2, 3: 0.3,  # Light tones: 20-30% synthetic
                4: 0.5,                   # Intermediate: 50% synthetic
                5: 0.7, 6: 0.8,           # Dark tones: 70-80% synthetic
            }
        else:
            self.synthetic_ratio_by_fst = synthetic_ratio_by_fst

        # Build index mapping
        self._build_index_mapping()

        print(f"\nMixed Dataset")
        print(f"  Real samples: {len(self.real_dataset)}")
        print(f"  Synthetic samples: {len(self.synthetic_dataset)}")
        print(f"  Mixed samples: {len(self.mixed_indices)}")
        print(f"  FST balancing: {balance_fst}")

        # Print FST-dependent ratios
        print(f"  Synthetic ratios by FST:")
        for fst, ratio in sorted(self.synthetic_ratio_by_fst.items()):
            print(f"    FST {fst}: {ratio*100:.0f}% synthetic")

    def _build_index_mapping(self):
        """
        Build mapping from mixed dataset index to (source, source_index).

        This implements FST-dependent sampling:
        - For each FST, determine synthetic ratio
        - Sample from real and synthetic accordingly
        """
        self.mixed_indices = []  # List of (source, index) tuples

        # Group real samples by FST
        real_by_fst = {i: [] for i in range(1, 7)}
        for idx in range(len(self.real_dataset)):
            sample = self.real_dataset[idx]
            fst = sample.get('fst', -1)
            if fst != -1 and 1 <= fst <= 6:
                real_by_fst[fst].append(idx)

        # Group synthetic samples by FST
        synthetic_by_fst = {i: [] for i in range(1, 7)}
        for idx in range(len(self.synthetic_dataset)):
            sample = self.synthetic_dataset[idx]
            fst = sample.get('fst', -1)
            if fst != -1 and 1 <= fst <= 6:
                synthetic_by_fst[fst].append(idx)

        # For each FST, mix real and synthetic
        for fst in range(1, 7):
            real_indices = real_by_fst[fst]
            synthetic_indices = synthetic_by_fst[fst]

            if len(real_indices) == 0 and len(synthetic_indices) == 0:
                continue

            # Get synthetic ratio for this FST
            synthetic_ratio = self.synthetic_ratio_by_fst.get(fst, 0.5)

            # Determine number of samples from each source
            if self.balance_fst:
                # Balance across FSTs (equal samples per FST)
                target_samples_per_fst = 2000  # Adjust based on desired dataset size
                num_synthetic = int(target_samples_per_fst * synthetic_ratio)
                num_real = target_samples_per_fst - num_synthetic
            else:
                # Use all real data, add synthetic according to ratio
                num_real = len(real_indices)
                num_synthetic = int(num_real * synthetic_ratio / (1 - synthetic_ratio + 1e-6))

            # Sample with replacement if needed
            sampled_real = np.random.choice(
                real_indices,
                size=min(num_real, len(real_indices)),
                replace=(num_real > len(real_indices))
            ).tolist()

            sampled_synthetic = np.random.choice(
                synthetic_indices,
                size=min(num_synthetic, len(synthetic_indices)),
                replace=(num_synthetic > len(synthetic_indices))
            ).tolist() if len(synthetic_indices) > 0 else []

            # Add to mixed indices
            self.mixed_indices.extend([('real', idx) for idx in sampled_real])
            self.mixed_indices.extend([('synthetic', idx) for idx in sampled_synthetic])

        # Shuffle mixed indices
        np.random.shuffle(self.mixed_indices)

    def __len__(self) -> int:
        return len(self.mixed_indices)

    def __getitem__(self, idx: int) -> Dict[str, Union[torch.Tensor, int]]:
        """
        Get mixed dataset item.

        Returns:
            Dictionary with same format as source datasets, plus:
                - is_synthetic: 0 for real, 1 for synthetic
        """
        source, source_idx = self.mixed_indices[idx]

        if source == 'real':
            sample = self.real_dataset[source_idx]
            sample['is_synthetic'] = 0
        else:
            sample = self.synthetic_dataset[source_idx]
            sample['is_synthetic'] = 1

        # Apply additional transforms if provided
        if self.transform is not None:
            image = sample['image']
            if isinstance(image, torch.Tensor):
                # Convert back to numpy for transforms
                image = image.permute(1, 2, 0).numpy()

            transformed = self.transform(image=image)
            sample['image'] = transformed['image']

        return sample


def create_fst_balanced_dataloader(
    real_dataset: Dataset,
    synthetic_dataset: Dataset,
    batch_size: int = 32,
    num_workers: int = 4,
    synthetic_ratio_by_fst: Optional[Dict[int, float]] = None,
) -> DataLoader:
    """
    Create DataLoader with FST-balanced sampling.

    Args:
        real_dataset: Real dataset
        synthetic_dataset: Synthetic dataset
        batch_size: Batch size
        num_workers: Number of dataloader workers
        synthetic_ratio_by_fst: FST-dependent synthetic ratios

    Returns:
        DataLoader with mixed dataset
    """
    mixed_dataset = MixedDataset(
        real_dataset=real_dataset,
        synthetic_dataset=synthetic_dataset,
        synthetic_ratio_by_fst=synthetic_ratio_by_fst,
        balance_fst=True,
    )

    dataloader = DataLoader(
        mixed_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
    )

    return dataloader


if __name__ == "__main__":
    """Demo of synthetic dataset."""
    print("=" * 70)
    print("Synthetic Dataset Demo")
    print("=" * 70)

    # Check if synthetic data exists
    synthetic_dir = Path("data/synthetic/fairskin")

    if not synthetic_dir.exists():
        print(f"\nSynthetic data directory not found: {synthetic_dir}")
        print("\nTo generate synthetic data:")
        print("  python experiments/augmentation/generate_fairskin.py")
    else:
        print(f"\nFound synthetic data directory: {synthetic_dir}")

        try:
            dataset = SyntheticDermoscopyDataset(
                synthetic_dir=str(synthetic_dir),
            )

            print(f"\nDataset loaded successfully!")
            print(f"Total samples: {len(dataset)}")

            # Show distributions
            print("\nClass distribution:")
            for dx, count in sorted(dataset.get_class_distribution().items()):
                print(f"  Class {dx}: {count}")

            print("\nFST distribution:")
            for fst, count in dataset.get_fst_distribution().items():
                print(f"  FST {fst}: {count}")

            # Load sample
            if len(dataset) > 0:
                print("\nLoading sample...")
                sample = dataset[0]
                print(f"  Image shape: {sample['image'].shape}")
                print(f"  Label: {sample['label']}")
                print(f"  FST: {sample['fst']}")
                print(f"  Is synthetic: {sample['is_synthetic']}")

        except Exception as e:
            print(f"\nError loading dataset: {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 70)
    print("Synthetic dataset demo complete")
    print("=" * 70)
